\section{Case Study}
\label{S:casestudy}

In January 2014, the east coast (PJM) electricity grid experienced an 86x increase in the price of electricity from \$31/MWh to \$2,680/MWh in a matter of 10 minutes. Similarly, the price spiked 32x from an average of \$25/MWh to \$800/MWh in July of 2015. This extreme price volatility has become the new norm in our electric grids. Building additional peak generation capacity is not environmentally or economically sustainable. Furthermore, the traditional view of energy efficiency does not address this need for \emph{Energy Flexibility}. The solution lies with Demand Response (DR) from the customer side - curtailing demand during peak capacity for financial incentives. However, this is a very hard problem for commercial, industrial and institutional plants, the largest electricity consumers.

Thus, the problem of energy management during a DR event makes an ideal case for DPC. In the following sections, we apply Optimal Experiment Design, DPC based on GPs and also perform Active Learning on a large scale EnergyPlus model to show how effectively DPC can provide a desired power curtailment as well as a desired thermal comfort. DPC builds predictive models of a building based on historical weather, schedule, set-points and electricity consumption data, while also learning from the actions of the building operator. These models are then used for synthesizing recommendations about the control actions that the operator needs to take, during a DR event, to obtain a given load curtailment while providing guarantees on occupant comfort and operations.

\subsection{Building Description}
\label{SS:casestudy:building}
We use two different DoE Commercial Reference Building (DoE CRB) simulated in EnergyPlus \cite{Deru2011} as the virtual test-bed building.
The first one is a 6 story \textit{hotel} consisting of 22 zone with a total area of 120,122 sq.ft, with a peal capacity of 400 kW.
The second building is a large 12 story \textit{office} building consisting of 19 zones with a total area of 498,588 sq.ft. 
Under peak load conditions the office can consume up to 1.4 MW of power. 
Developing a high fidelity physics-based model for these buildings would require massive cost and years of efforts.
Leveraging machine learning algorithms, we can now do both prediction and control with high confidence at a very low cost.

We use the following data to validate our results. We limit to data which can be measured directly from installed sensors like thermostats, multimeters and weather forecasts, thus making it scalable to any other building or a campus of buildings.

\textit{Weather variables \(d^w\):} outside temperature and humidity - these features are defined in a weather file in EnergyPlus.

\textit{Proxy features \(d^p\):} time of day, day of week - these features are a good indicator of occupancy and periodic trends.
%\textit{Fixed schedules  \(d^s\):} kitchen cooling set point, corridor cooling set point - these set points follow predefined rules. 

\textit{Control variables \(u\):} cooling set point, supply air temperature and chilled water set point - these set points will be optimized in the MPC problem for Power Tracking Reference Control in Sec.~\ref{SS:power_tracking} and Optimal Energy Management in Sec.~\ref{SS:energy_management}.

\textit{Output variable \(y\):} total power consumption - this is output of interest which we will predict using all the above features in the GP model.

\subsection{Structure of  Gaussian Process Models}
\label{SS:casestudy:gp}

For MPC, we require a predictive model for each time step in the horizon.
\todo[inline]{This is not true! Currently we use a single GP and propagate the mean over the time steps.}
We learn several GP models, one for each prediction step \( \tau \in \{0,\dots,N-1\}\):
\begin{gather}
\label{E:gp:casestudy}
y_{t+\tau|t} | x_{t+\tau|t} \sim \GaussianDist{\bar{y}_{t+\tau|t}}{\sigma^2_{y,t+\tau|t}}, \\
x_{t}\!=\![y_{t-l}, \dots, y_{t-1}, u_{t-m}, \dots, u_t, w_{t-p}, \dots, w_{t-1}, w_t], \nonumber
\end{gather}
where \(w:=[d^w, d^p, d^s]\). We assume that at time \(t\), \(w_{t+\tau}\) are available \(\forall \tau \) from forecasts or fixed rules as applicable.

As for the mean and covariance functions to define the structure of GP in \eqref{E:gp:prior}, we use a constant mean \(\mu\) and a kernel function \(k(x,x')\) which is a mixture of constant kernel \(k_1(x,x')\), squared exponential kernel \(k_2(x,x')\) and rational quadratic kernel \(k_3(x,x')\) defined by
\begin{gather}
k_1(x,x')  = k, \nonumber\\
k_2(x,x') = \sigma_{f_2}^2 \exp \left( -\frac{1}{2} \sum_{d=1}^D \frac{(x_d-x_d')}{{\lambda_d^2}}^2 \right),
 \nonumber\\
 k_3(x,x') = \sigma_{f_3}^2  \left( 1+ \frac{1}{2\alpha} \sum_{d=1}^D \frac{(x_d-x_d')}{{\lambda^2}}^2 \right)^{-\alpha},  \nonumber\\
k(x,x') = \left(k_1(x,x') + k_2(x,x')\right)*k_3(x,x').
\end{gather}
Here, \(k_3(x,x')\) is applied to only nontemporal features like time of day and day of week, while \(k_1(x,x')\) and \(k_2(x,x')\) are applied to all the remaining features as proposed in \cite{nghiemetal16gp}. For each model in \eqref{E:gp:casestudy}, we optimize the parameters \(\theta = [\mu, k, \sigma_{f_2}, \lambda_d, \sigma_{f_3}, \alpha, \lambda] \) using GPML \cite{Rasmussen2010}. After training, the less important features, i.e.~features with high \(\lambda_d\) are removed and the models are trained again. We denote this final selection by \(\theta^\star\).

\todo[inline]{model validation?}

\subsection{Optimal Experiment Design}

\begin{figure*}[t]
	\centering
	\setlength\fwidth{0.46\textwidth}
	\setlength\hwidth{0.2\textwidth}
	\input{figures/casestudy-oed-hotel.tex}
	\input{figures/casestudy-oed-office.tex}
	\caption{Comparison of model accuracies for different experiments: OED based on information gain (IG),  OED based on maximum variance (MV), uniform random sampling (Uniform) and sampling using pseudo random binary signals (PRBS) for two buildings: hotel (left) and office (right). RMSE denotes root mean square error and MSLL mean standardized log loss.}
	\captionsetup{justification=centering}
	\label{F:casestudy:oed}
\end{figure*}

OED is powerful when limited data are available for training. 
To demonstrate this, using Algo.~\ref{A:oed:sequential}, we begin the experiment by assigning \(\GaussianDist{0}{1}\) priors to \(\log (\theta) \) elementwise, except for \(\mu\), since GPML applies gradient descent directly on \(\log \theta\).
For OED, we only require the first model with \(\tau=0\) in \eqref{E:gp:casestudy}. So we simplify the notation by denoting \(t|t\) by \(t\).
Now, the goal at time \(t\) is to determine what should be the optimal cooling set point \(u_{\mathrm{clg},t}\), supply air temperature \(u_{\mathrm{sat},t}\), and chilled water temperature \(u_{\mathrm{chw},t}\) which when applied to the building will require power consumption \(y_t\) such that \((x_t,y_t)\) can be used to learn \(\theta\) as efficiently as possible.
We use the lagged terms of the power consumption, proxy variables, weather variables and their lagged terms and their lagged terms to define \(x_t(u_{\mathrm{clg,t}},u_{\mathrm{sat,t}},u_{\mathrm{chw,t}})\).
In practice, the chilled water temperature cannot be changed by more than \(0.15^o\mathrm{C/min}\). Keep this and thermal comfort into consideration, we consider the following operation constraints:
\begin{gather}
22^o\mathrm{C} \leq u_{\mathrm{clg,t}} \leq  26^o\mathrm{C}, \nonumber \\
12^o\mathrm{C} \leq u_{\mathrm{sat,t}} \leq  14^o\mathrm{C}, \nonumber \\
 3.7^o\mathrm{C} \leq u_{\mathrm{chw,t}} \leq  9.7^o\mathrm{C},\label{E:operation_constraints} \\
| u_{\mathrm{chw},t} - u_{\mathrm{chw},t-1}| \leq  2^o\mathrm{C}. \nonumber
\end{gather}
Finally, we solve the optimization below every \(15 \mathrm{min}\) to calculate optimal inputs for OED:
\begin{align}
\label{E:casestudy:oed}
\maximize_{u_{\mathrm{clg},t},u_{\mathrm{sat},t},u_{\mathrm{chw},t}} & \ \ \ \frac{1}{2}\log\left(\frac{\sigma^2_{t}(x_t)+a^T(x_t)\Sigma a(x_t)}{\sigma^2_{t}(x_t)}\right) \\
\st &  \ \ \ \  \text{operations constraints } \eqref{E:operation_constraints}.\nonumber
\end{align}

The results for experiment design in closed-loop with the EnergyPlus building models described in Sec.~\ref{SS:casestudy:building} are shown in Fig.~\ref{F:casestudy:oed}.
We compare 4 different methods: OED based on maximum information gain (IG), OED based on maximum variance (MV), uniform random sampling (Uniform) and sampling using pseudo random binary signals (PRBS).
The inputs \(u_{\mathrm{clg,t}},u_{\mathrm{sat,t}},u_{\mathrm{chw,t}}\) generated via OED or random sampling are applied to the building every \(15 \mathrm{min}\).
We repeat OED/random sampling continuously for \(14\) days and learn a model at the end of each day using the data generated until that time. 
For example, at the end day of day \(3\) we have \(3\times96\) samples, at day \(7\) we have \(7\times96\) samples and so on. 
As the days progress, we add more training samples and therefore the model accuracy is expected to increase with time. 
This is visible in both metrics root mean square error (RMSE) and mean standardized log loss (MSLL) for both buildings.

For OED based on information gain as well as maximum variance, the learning rate is much faster than any random sampling.
For the hotel building on the left, information gain is the best in terms of RMSE and MSLL.
Uniform random sampling and  PRBS are far worse in both metrics for first \(7-10\) days (\(\sim200\) hrs), beyond we obtain sufficient data that it is hard to distinguish between the performance and model accuracies.
For the office building on the right, IG is better than MV in terms of MSLL for all days, while MV shows faster learning rate showing lower RMSE. 
Thus for the office building, OED based on IG and MV are comparable. 
With the random sampling, we observe the same trend as before, i.e.~much worse for first \(\sim200\) hrs of experiment after which model accuracies are similar for IG, MV, Uniform and PRBS.

\subsection{Power Reference Tracking Control}
\label{SS:power_tracking}

This section formulates a model predictive control (MPC) approach for the demand tracking problem.
We consider a building, which responds to various setpoints resulting in power demand variations, and a battery, whose state of charge (SoC) can be measured and whose charge/discharge power can be controlled.
The building's response to the setpoint changes is modeled by a GP.
The battery helps improve the tracking quality by absorbing the prediction uncertainty of the GP.
A controller computes the setpoint values for the building and the power of the battery to optimally track the reference demand signal.

For simplicity, we assume an ideal lossless battery model
\begin{equation}
\label{eq:battery-model}
s_{t+1} = s_t + T \Pbatt_t
\end{equation}
where \(\Pbatt_t\) is the battery's power during the time step \(t\) and \(s\) is the battery's SoC.
Here, \(\Pbatt\) is positive if the battery is charging and negative if discharging.
The battery is subject to two operational constraints:
its power is bounded by \(\Pbmin \leq \Pbatt_t \leq \Pbmax\), 
and its SoC must stay in a safe range \(\SOCmin \leq s_t \leq\SOCmax\) where \(\SOCmax\) is the fully-charged level and \(\SOCmin\) is the lowest safe discharged level. 

The building and the battery are linked via the power tracking constraint which states that \(p_t = y_t + b_t\) should track the reference \(r_t\) at any time \(t\). Therefore, our objective is to minimize \(\delta_t = r_t - p_t\).
In this way, the battery helps reject the uncertainty of the GP and acts as an energy buffer to increase the tracking capability of the system. 
The controller tries to keep \(\delta_t = 0\), however when exact tracking is impossible, it will maintain the operational safety of the system while keeping \(\delta_t\)  as small as possible.
The bounds on the battery's power and SoC lead to corresponding chance constraints.
We wish to guarantee that at each time step, the power and SoC constraints are satisfied with probability at least \((1 - \epsilon_p)\) and  at least \((1 - \epsilon_s)\), respectively, where \(0 < \epsilon_p, \epsilon_s \leq \frac{1}{2}\) are given constants.
Specifically, for each \(\tau\) in the horizon,
	\begin{gather}
	\label{E:battery_chance}
	\Pr\left( \Pbmin \leq b_{\tau+t|t}\leq \Pbmax \right) \geq 1 - \epsilon_p  \\
	\label{E:SoC_chance}
	\Pr\left( \SOCmin \leq s_{\tau+t|t} \leq \SOCmax \right) \geq 1 - \epsilon_s 
	\end{gather}
where \(b_{t+\tau|t}\) and \(s_{t+\tau|t}\) are Gaussian random variables whose mean and variance are given by
\begin{gather}
\label{E:battery_dist}
\bar{b}_{t+\tau|t}= r_{t} - \delta_{t+\tau|t} - \bar{y}_{t+\tau|t}, \ \ 
\sigma^2_{b,t+\tau|t} =  \sigma^2_{y,t+\tau|t} \text, \\
\label{E:SoC_dist}
\bar{s}_{t+\tau+1|t}= s_t + T \textstyle\sum_{k=t}^{t+\tau} \predict{k}{\bar{\Pbatt}}, \,
\predict{s,\tau+1}{\sigma^2} = T^2 \textstyle\sum_{k=t}^{t+\tau} \predict{y,k}{\sigma^2}
\end{gather}
Further details on modeling we refer the reader to our previous work \cite{nghiemetal16gp}.
To this end, to track a given reference power signal, we solve the following stochastic optimization problem to optimize \(\delta_{\tau+t|t},u_{\mathrm{clg},\tau+t|t},u_{\mathrm{sat},\tau+t|t},u_{\mathrm{chw},\tau+t|t} \ \forall \tau \in \{0,\dots,N-1\}\)
\begin{align}
\label{E:casestudy:mpc}
\minimize_{\delta, u} & \ \ \ \ \ \ \ \ \ \sum_{\tau=0}^{N-1} (\delta_{\tau+t|t})^2 + \sigma_{y,\tau+t|t}^2\\
\st &  \ \ \ \  \text{dynamics constraints } \eqref{E:gp:casestudy}, \eqref{E:battery_chance} - \eqref{E:SoC_dist} \nonumber \\
&  \ \ \ \  \text{operation constraints } \eqref{E:operation_constraints}. \nonumber
\end{align}
The term \( \sigma_{y,\tau+t|t}^2\) in the objective functions ensures control setpoints where model is more confident.
At time \(t\), we solve for \(u^*_{t|t},\dots,u^*_{t+N-1|t} \), apply the first input \(u^*_{t|t} \) to the building, and proceed to the next time step.

\todo[inline]{results}

\subsection{Optimizing energy usage under operation constraints}
\label{SS:energy_management}

\todo[inline]{optimization problem}
%\begin{figure}[!tb]
%	\centering
%	\missingfigure[figwidth=20pc]{}
%	\caption{}
%	\captionsetup{justification=centering}
%	\label{F:MPC2}
%\end{figure}

\subsection{Active Learning}
\label{SS:casestudy:active}

\subsection{Discussion}

\todo[inline]{computational complexity}
