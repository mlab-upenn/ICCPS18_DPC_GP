\begin{abstract}
  Building physics-based models of complex physical systems like buildings and chemical plants is extremely cost and time prohibitive for applications such as real-time optimal control, production planning and supply chain logistics.  Machine learning algorithms can reduce this cost and time complexity, and are, consequently, more scalable for large-scale physical systems. However, there are many practical challenges that must be addressed before employing machine learning for closed-loop control. This paper proposes the use of Gaussian Processes (GP) for learning control-oriented models: (1) We develop methods for the optimal experiment design (OED) of functional tests to learn models of a physical system, subject to stringent operational constraints and limited availability of the system. Using a Bayesian approach with GP, our methods seek to select the most informative data for optimally updating an existing model. (2) We also show that black-box GP models can be used for receding horizon optimal control with probabilistic guarantees on constraint satisfaction through chance constraints.
  (3) We further propose an online method for continuously improving the GP model in closed-loop with a real-time controller.
  Our methods are demonstrated and validated in a case study of building energy control and Demand Response.
%  We show that OED achieves faster learning rate than random sampling, reducing the duration of functional tests by upto 50\%. The GP controller provides the desired curtailment perfectly with maximum 1.7\% prediction error.
\end{abstract}